{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9-wxl7hek2m",
        "outputId": "7d4a194c-df0b-4523-c347-d1d32bdee16c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\selen\\AppData\\Local\\Temp\\ipykernel_9008\\3184787466.py:6: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  pd.set_option('max_colwidth', -1)\n"
          ]
        }
      ],
      "source": [
        "# pandas to open data files & processing it.\n",
        "import pandas as pd\n",
        "# to see all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "# To see whole text\n",
        "pd.set_option('max_colwidth', -1)\n",
        "\n",
        "# numpy for numeric data processing\n",
        "import numpy as np\n",
        "\n",
        "# keras for deep learning model creation\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "\n",
        "# to fix random seeds\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Regular Expression for text cleaning\n",
        "import re\n",
        "\n",
        "# to track the progress - progress bar\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "Rg-L-HPqe1O1",
        "outputId": "eb0584f6-219e-481b-9bcf-03003d8c333d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100000, 11)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "      <th>author</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>score</th>\n",
              "      <th>ups</th>\n",
              "      <th>downs</th>\n",
              "      <th>date</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>parent_comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NC and NH.</td>\n",
              "      <td>Trumpbart</td>\n",
              "      <td>politics</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-10</td>\n",
              "      <td>2016-10-16 23:55:23</td>\n",
              "      <td>Yeah, I get that argument. At this point, I'd prefer is she lived in NC as well.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>You do know west teams play against west teams more than east teams right?</td>\n",
              "      <td>Shbshb906</td>\n",
              "      <td>nba</td>\n",
              "      <td>-4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-11</td>\n",
              "      <td>2016-11-01 00:24:10</td>\n",
              "      <td>The blazers and Mavericks (The wests 5 and 6 seed) did not even carry a good enough record to make the playoffs in the east last year.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>They were underdogs earlier today, but since Gronk's announcement this afternoon, the Vegas line has moved to patriots -1</td>\n",
              "      <td>Creepeth</td>\n",
              "      <td>nfl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-09</td>\n",
              "      <td>2016-09-22 21:45:37</td>\n",
              "      <td>They're favored to win.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>This meme isn't funny none of the \"new york nigga\" ones are.</td>\n",
              "      <td>icebrotha</td>\n",
              "      <td>BlackPeopleTwitter</td>\n",
              "      <td>-8</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-10</td>\n",
              "      <td>2016-10-18 21:03:47</td>\n",
              "      <td>deadass don't kill my buzz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I could use one of those tools.</td>\n",
              "      <td>cush2push</td>\n",
              "      <td>MaddenUltimateTeam</td>\n",
              "      <td>6</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-12</td>\n",
              "      <td>2016-12-30 17:00:13</td>\n",
              "      <td>Yep can confirm I saw the tool they use for that. It was made by our boy EASports_MUT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  label  \\\n",
              "0  0           0       \n",
              "1  1           0       \n",
              "2  2           0       \n",
              "3  3           0       \n",
              "4  4           0       \n",
              "\n",
              "                                                                                                                     comment  \\\n",
              "0  NC and NH.                                                                                                                  \n",
              "1  You do know west teams play against west teams more than east teams right?                                                  \n",
              "2  They were underdogs earlier today, but since Gronk's announcement this afternoon, the Vegas line has moved to patriots -1   \n",
              "3  This meme isn't funny none of the \"new york nigga\" ones are.                                                                \n",
              "4  I could use one of those tools.                                                                                             \n",
              "\n",
              "      author           subreddit  score  ups  downs     date  \\\n",
              "0  Trumpbart  politics            2     -1   -1      2016-10   \n",
              "1  Shbshb906  nba                -4     -1   -1      2016-11   \n",
              "2  Creepeth   nfl                 3      3    0      2016-09   \n",
              "3  icebrotha  BlackPeopleTwitter -8     -1   -1      2016-10   \n",
              "4  cush2push  MaddenUltimateTeam  6     -1   -1      2016-12   \n",
              "\n",
              "           created_utc  \\\n",
              "0  2016-10-16 23:55:23   \n",
              "1  2016-11-01 00:24:10   \n",
              "2  2016-09-22 21:45:37   \n",
              "3  2016-10-18 21:03:47   \n",
              "4  2016-12-30 17:00:13   \n",
              "\n",
              "                                                                                                                           parent_comment  \n",
              "0  Yeah, I get that argument. At this point, I'd prefer is she lived in NC as well.                                                        \n",
              "1  The blazers and Mavericks (The wests 5 and 6 seed) did not even carry a good enough record to make the playoffs in the east last year.  \n",
              "2  They're favored to win.                                                                                                                 \n",
              "3  deadass don't kill my buzz                                                                                                              \n",
              "4  Yep can confirm I saw the tool they use for that. It was made by our boy EASports_MUT                                                   "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sarcasm_data = pd.read_csv(\"sarcasm.csv\")\n",
        "print(sarcasm_data.shape)\n",
        "sarcasm_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "27wToexje4eE",
        "outputId": "ae310723-acbe-42bf-854a-a7d4afc39c34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NC and NH.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>You do know west teams play against west teams more than east teams right?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>They were underdogs earlier today, but since Gronk's announcement this afternoon, the Vegas line has moved to patriots -1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>This meme isn't funny none of the \"new york nigga\" ones are.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I could use one of those tools.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  label  \\\n",
              "0  0           0       \n",
              "1  1           0       \n",
              "2  2           0       \n",
              "3  3           0       \n",
              "4  4           0       \n",
              "\n",
              "                                                                                                                     comment  \n",
              "0  NC and NH.                                                                                                                 \n",
              "1  You do know west teams play against west teams more than east teams right?                                                 \n",
              "2  They were underdogs earlier today, but since Gronk's announcement this afternoon, the Vegas line has moved to patriots -1  \n",
              "3  This meme isn't funny none of the \"new york nigga\" ones are.                                                               \n",
              "4  I could use one of those tools.                                                                                            "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sarcasm_data.drop(['author', 'subreddit', 'score', 'ups', 'downs', 'date', 'created_utc', 'parent_comment'], axis=1, inplace=True)\n",
        "# remove empty rows\n",
        "sarcasm_data.dropna(inplace=True)\n",
        "sarcasm_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr2nLANRe7SZ",
        "outputId": "25da141c-7ae3-4fac-8ba5-3c68b842af3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    57690\n",
              "1    42308\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sarcasm_data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mJfsYeD_e9tn"
      },
      "outputs": [],
      "source": [
        "mispell_dict = {\"ain't\": \"is not\", \"cannot\": \"can not\", \"aren't\": \"are not\", \"can't\": \"can not\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",\n",
        "                \"doesn't\": \"does not\",\n",
        "                \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
        "                \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\", \"I'm\": \"I am\",\n",
        "                \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
        "                \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
        "                \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n",
        "                \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"so's\": \"so as\", \"this's\": \"this is\", \"that'd\": \"that would\",\n",
        "                \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\", \"they'd\": \"they would\",\n",
        "                \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n",
        "                \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
        "                \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\",\n",
        "                \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"wont\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n",
        "                \"wouldn't\": \"would not\",\n",
        "                \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\",\n",
        "                \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color',\n",
        "                'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor',\n",
        "                'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What',\n",
        "                'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I',\n",
        "                'theBest': 'the best', 'howdoes': 'how does', 'Etherium': 'Ethereum',\n",
        "                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what',\n",
        "                'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}\n",
        "\n",
        "mispell_dict = {k.lower(): v.lower() for k, v in mispell_dict.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-3V7Ck7mfBp9"
      },
      "outputs": [],
      "source": [
        "def preprocessing_text(s):\n",
        "    # making our string lowercase & removing extra spaces\n",
        "    s = str(s).lower().strip()\n",
        "    \n",
        "    # remove contractions.\n",
        "    s = \" \".join([mispell_dict[word] if word in mispell_dict.keys() else word for word in s.split()])\n",
        "    \n",
        "    # removing \\n\n",
        "    s = re.sub('\\n', '', s)\n",
        "    \n",
        "    # put spaces before & after punctuations to make words seprate. Like \"king?\" to \"king\", \"?\".\n",
        "    s = re.sub(r\"([?!,+=—&%\\'\\\";:¿।।।|\\(\\){}\\[\\]//])\", r\" \\1 \", s)\n",
        "    \n",
        "    # Remove more than 2 continues spaces with 1 space.\n",
        "    s = re.sub('[ ]{2,}', ' ', s).strip()\n",
        "    \n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "slh-tR6efECO",
        "outputId": "99059e56-e910-4407-ba22-843c9f3ad7d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>nc and nh.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>you do know west teams play against west teams more than east teams right ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>they were underdogs earlier today , but since gronk ' s announcement this afternoon , the vegas line has moved to patriots -1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>this meme is not funny none of the \" new york nigga \" ones are.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>i could use one of those tools.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  label  \\\n",
              "0  0           0       \n",
              "1  1           0       \n",
              "2  2           0       \n",
              "3  3           0       \n",
              "4  4           0       \n",
              "\n",
              "                                                                                                                         comment  \n",
              "0  nc and nh.                                                                                                                     \n",
              "1  you do know west teams play against west teams more than east teams right ?                                                    \n",
              "2  they were underdogs earlier today , but since gronk ' s announcement this afternoon , the vegas line has moved to patriots -1  \n",
              "3  this meme is not funny none of the \" new york nigga \" ones are.                                                                \n",
              "4  i could use one of those tools.                                                                                                "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# apply preprocessing_text function\n",
        "sarcasm_data['comment'] = sarcasm_data['comment'].apply(preprocessing_text)\n",
        "sarcasm_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7MQCLxHXfGKI"
      },
      "outputs": [],
      "source": [
        "# total unique words we are going to use.\n",
        "TOTAL_WORDS = 40000\n",
        "\n",
        "# max number of words one sentence can have\n",
        "MAX_LEN = 50\n",
        "\n",
        "# width of of 1D embedding vector\n",
        "EMBEDDING_SIZE = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp1htr19fJAe",
        "outputId": "2a841d5b-1c30-40fa-cc63-c2140dffdaf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 2.53 s\n",
            "Wall time: 2.52 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "tokenizer = Tokenizer(num_words=TOTAL_WORDS)\n",
        "tokenizer.fit_on_texts(list(sarcasm_data['comment']))\n",
        "\n",
        "train_data = tokenizer.texts_to_sequences(sarcasm_data['comment'])\n",
        "train_data = pad_sequences(train_data, maxlen = MAX_LEN)\n",
        "target = sarcasm_data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "B01ZefcafK-O"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c251bf60983347519c4548d6c59a87f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 2min 18s\n",
            "Wall time: 2min 29s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "EMBEDDING_FILE = 'crawl-300d-2M.vec'\n",
        "\n",
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in tqdm(open(EMBEDDING_FILE, encoding='utf-8')))\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(TOTAL_WORDS, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, EMBEDDING_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "caYWYKsIfOtu"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a0eaaee4c78470c9080a603e0d9e9cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/49192 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for word, i in tqdm(word_index.items()):\n",
        "    if i >= TOTAL_WORDS: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MYukRhrnfXA7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40000, 300)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UdI1DNAhfRDC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\torch\\random.py:42: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
            "  return default_generator.manual_seed(seed)\n"
          ]
        }
      ],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "# We fix all the random seed so that, we can reproduce the results.\n",
        "seed_everything(2020)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "StnYgtz9fUNl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 50)]              0         \n",
            "                                                                 \n",
            " embedding_14 (Embedding)    (None, 50, 300)           12000000  \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirecti  (None, 50, 256)          439296    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " global_max_pooling1d_12 (Gl  (None, 256)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,457,857\n",
            "Trainable params: 12,457,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "input_layer = keras.Input(shape=(MAX_LEN,))\n",
        "\n",
        "embedding_layer = Embedding(TOTAL_WORDS, EMBEDDING_SIZE, weights = [embedding_matrix])(input_layer)\n",
        "\n",
        "LSTM_layer = Bidirectional(LSTM(128, return_sequences = True))(embedding_layer)\n",
        "maxpool_layer = GlobalMaxPool1D()(LSTM_layer)\n",
        "\n",
        "dense_layer_1 = Dense(64, activation=\"relu\")(maxpool_layer)\n",
        "dropout_1 = Dropout(0.5)(dense_layer_1)\n",
        "\n",
        "dense_layer_2 = Dense(32, activation=\"relu\")(dropout_1)\n",
        "dropout_2 = Dropout(0.5)(dense_layer_2)\n",
        "\n",
        "output_layer = Dense(1, activation=\"sigmoid\")(dropout_2)\n",
        "\n",
        "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8HuclV87fbPA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
          ]
        }
      ],
      "source": [
        "plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "5eL7k2JMfeB0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "157/157 [==============================] - 153s 945ms/step - loss: 0.6233 - accuracy: 0.6575 - val_loss: 0.5654 - val_accuracy: 0.7154\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 178s 1s/step - loss: 0.5450 - accuracy: 0.7354 - val_loss: 0.5678 - val_accuracy: 0.7061\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 512\n",
        "EPOCHS = 2\n",
        "\n",
        "history = model.fit(\n",
        "    train_data, target,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    # We are using randomly selected 20% sentences as validation data.\n",
        "    validation_split=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "JsufqR7Ufgs9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57071</th>\n",
              "      <td>57071</td>\n",
              "      <td>1</td>\n",
              "      <td>i find the term \" meat shop \" very offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72552</th>\n",
              "      <td>72552</td>\n",
              "      <td>1</td>\n",
              "      <td>i believe the proper term is \" latinex \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68128</th>\n",
              "      <td>68128</td>\n",
              "      <td>1</td>\n",
              "      <td>that is just gang violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10415</th>\n",
              "      <td>10415</td>\n",
              "      <td>1</td>\n",
              "      <td>yea just look at what they were wearing , they were practically asking for it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1047</th>\n",
              "      <td>1047</td>\n",
              "      <td>1</td>\n",
              "      <td>the heathens deserved it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45581</th>\n",
              "      <td>45581</td>\n",
              "      <td>1</td>\n",
              "      <td>deport him !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12491</th>\n",
              "      <td>12491</td>\n",
              "      <td>1</td>\n",
              "      <td>wait for 8k @ 240fps.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31139</th>\n",
              "      <td>31139</td>\n",
              "      <td>1</td>\n",
              "      <td>yeah no one will die next year.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80329</th>\n",
              "      <td>80329</td>\n",
              "      <td>1</td>\n",
              "      <td>but.. but muh freedoms !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41111</th>\n",
              "      <td>41111</td>\n",
              "      <td>1</td>\n",
              "      <td>so which side are you on ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88776</th>\n",
              "      <td>88776</td>\n",
              "      <td>1</td>\n",
              "      <td>or... you could delete a character today , rush level it to 40 and then go 0 / 7 by the reset !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10451</th>\n",
              "      <td>10451</td>\n",
              "      <td>1</td>\n",
              "      <td>but real \" big boys \" with small apartments keep theirs in the bathroom.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96242</th>\n",
              "      <td>96242</td>\n",
              "      <td>1</td>\n",
              "      <td>no you should not buy r6 : s. everyone in this sub plays the game ironically and none of us actually like the game</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64004</th>\n",
              "      <td>64004</td>\n",
              "      <td>1</td>\n",
              "      <td>you could also reload 5.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97721</th>\n",
              "      <td>97721</td>\n",
              "      <td>1</td>\n",
              "      <td>coz flashy neon skins are way better than shitty camouflage skins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32580</th>\n",
              "      <td>32580</td>\n",
              "      <td>1</td>\n",
              "      <td>not overpowered at all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20732</th>\n",
              "      <td>20732</td>\n",
              "      <td>1</td>\n",
              "      <td>see , that is just how conniving and devious ctr is , posting thousands of anti-clinton shitposts to throw true patriot trump supporters off the scent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30900</th>\n",
              "      <td>30900</td>\n",
              "      <td>1</td>\n",
              "      <td>nope sorry has to be every game dont you know about anything</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32912</th>\n",
              "      <td>32912</td>\n",
              "      <td>1</td>\n",
              "      <td>which is which ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88107</th>\n",
              "      <td>88107</td>\n",
              "      <td>1</td>\n",
              "      <td>that is what dating a kardashian can do to you.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  label  \\\n",
              "57071  57071       1       \n",
              "72552  72552       1       \n",
              "68128  68128       1       \n",
              "10415  10415       1       \n",
              "1047   1047        1       \n",
              "45581  45581       1       \n",
              "12491  12491       1       \n",
              "31139  31139       1       \n",
              "80329  80329       1       \n",
              "41111  41111       1       \n",
              "88776  88776       1       \n",
              "10451  10451       1       \n",
              "96242  96242       1       \n",
              "64004  64004       1       \n",
              "97721  97721       1       \n",
              "32580  32580       1       \n",
              "20732  20732       1       \n",
              "30900  30900       1       \n",
              "32912  32912       1       \n",
              "88107  88107       1       \n",
              "\n",
              "                                                                                                                                                       comment  \n",
              "57071  i find the term \" meat shop \" very offensive                                                                                                             \n",
              "72552  i believe the proper term is \" latinex \"                                                                                                                 \n",
              "68128  that is just gang violence                                                                                                                               \n",
              "10415  yea just look at what they were wearing , they were practically asking for it.                                                                           \n",
              "1047   the heathens deserved it                                                                                                                                 \n",
              "45581  deport him !                                                                                                                                             \n",
              "12491  wait for 8k @ 240fps.                                                                                                                                    \n",
              "31139  yeah no one will die next year.                                                                                                                          \n",
              "80329  but.. but muh freedoms !                                                                                                                                 \n",
              "41111  so which side are you on ?                                                                                                                               \n",
              "88776  or... you could delete a character today , rush level it to 40 and then go 0 / 7 by the reset !                                                          \n",
              "10451  but real \" big boys \" with small apartments keep theirs in the bathroom.                                                                                 \n",
              "96242  no you should not buy r6 : s. everyone in this sub plays the game ironically and none of us actually like the game                                       \n",
              "64004  you could also reload 5.56                                                                                                                               \n",
              "97721  coz flashy neon skins are way better than shitty camouflage skins                                                                                        \n",
              "32580  not overpowered at all                                                                                                                                   \n",
              "20732  see , that is just how conniving and devious ctr is , posting thousands of anti-clinton shitposts to throw true patriot trump supporters off the scent.  \n",
              "30900  nope sorry has to be every game dont you know about anything                                                                                             \n",
              "32912  which is which ?                                                                                                                                         \n",
              "88107  that is what dating a kardashian can do to you.                                                                                                          "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sarcasm_data[sarcasm_data['label']==1].sample(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "aNPRqhhjfkge"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sun rises from the east\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "         1701, 12991,    57,     1,  1168]])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence = \"sun rises from the east\"\n",
        "sentence = preprocessing_text(sentence)\n",
        "print(sentence)\n",
        "\n",
        "sentence = tokenizer.texts_to_sequences([sentence])\n",
        "sentence = pad_sequences(sentence, maxlen = MAX_LEN)\n",
        "sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "uC2gOeYNfmlM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 660ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.32464248"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make the prediction.\n",
        "prediction = model.predict(sentence)\n",
        "prediction[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "UVbwXr2ufo8G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "So, it's saying sentence have probability of 32.464 percent\n"
          ]
        }
      ],
      "source": [
        "print(\"So, it's saying sentence have probability of %.3f percent\"%(prediction[0][0]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "hh0ggVm3fq8_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is not it great that , your girlfriend dumped you ?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     2,     8,     7,   128,\n",
              "           10,    38,  1638, 18460,     6]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence = \"Isn't it great that, your girlfriend dumped you?\"\n",
        "sentence = preprocessing_text(sentence)\n",
        "print(sentence)\n",
        "\n",
        "sentence = tokenizer.texts_to_sequences([sentence])\n",
        "sentence = pad_sequences(sentence, maxlen = MAX_LEN)\n",
        "sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "C4YcAqycftAA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.66203296"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make the prediction.\n",
        "prediction = model.predict(sentence)\n",
        "prediction[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "xFdFQmlffu1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "So, it's saying sentence have probability of 66.203 percent\n"
          ]
        }
      ],
      "source": [
        "print(\"So, it's saying sentence have probability of %.3f percent\"%(prediction[0][0]*100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
